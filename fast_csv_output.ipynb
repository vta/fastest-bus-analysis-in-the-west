{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "# url = 'https://opendata.arcgis.com/datasets/490db54636704d35aae661a12c12e9a0_0.geojson'\n",
    "# r = requests.get(url, allow_redirects=True)\n",
    "# open('Bus_Stop_Inventory.geojson', 'wb').write(r.content)\n",
    "geo_df = gpd.read_file('Bus_Stop_Inventory.geojson')\n",
    "\n",
    "routes_shapes = gpd.read_file('routes_shapes.geojson')\n",
    "crs = routes_shapes.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/bus_stop_data_analysis_dwell_304.csv\n",
      "./results/bus_stop_data_analysis_dwell_34.csv\n",
      "./results/bus_stop_data_analysis_dwell_35.csv\n",
      "./results/bus_stop_data_analysis_dwell_37.csv\n",
      "./results/bus_stop_data_analysis_dwell_23.csv\n",
      "./results/bus_stop_data_analysis_dwell_22.csv\n",
      "./results/bus_stop_data_analysis_dwell_104.csv\n",
      "./results/bus_stop_data_analysis_dwell_32.csv\n",
      "./results/bus_stop_data_analysis_dwell_26.csv\n",
      "./results/bus_stop_data_analysis_dwell_27.csv\n",
      "./results/bus_stop_data_analysis_dwell_101.csv\n",
      "./results/bus_stop_data_analysis_dwell_103.csv\n",
      "./results/bus_stop_data_analysis_dwell_25.csv\n",
      "./results/bus_stop_data_analysis_dwell_31.csv\n",
      "./results/bus_stop_data_analysis_dwell_19.csv\n",
      "./results/bus_stop_data_analysis_dwell_18.csv\n",
      "./results/bus_stop_data_analysis_dwell_328.csv\n",
      "./results/bus_stop_data_analysis_dwell_102.csv\n",
      "./results/bus_stop_data_analysis_dwell_57.csv\n",
      "./results/bus_stop_data_analysis_dwell_81.csv\n",
      "./results/bus_stop_data_analysis_dwell_42.csv\n",
      "./results/bus_stop_data_analysis_dwell_68.csv\n",
      "./results/bus_stop_data_analysis_dwell_54.csv\n",
      "./results/bus_stop_data_analysis_dwell_40.csv\n",
      "./results/bus_stop_data_analysis_dwell_82.csv\n",
      "./results/bus_stop_data_analysis_dwell_55.csv\n",
      "./results/bus_stop_data_analysis_dwell_45.csv\n",
      "./results/bus_stop_data_analysis_dwell_201.csv\n",
      "./results/bus_stop_data_analysis_dwell_200.csv\n",
      "./results/bus_stop_data_analysis_dwell_46.csv\n",
      "./results/bus_stop_data_analysis_dwell_52.csv\n",
      "./results/bus_stop_data_analysis_dwell_53.csv\n",
      "./results/bus_stop_data_analysis_dwell_47.csv\n",
      "./results/bus_stop_data_analysis_dwell_62.csv\n",
      "./results/bus_stop_data_analysis_dwell_89.csv\n",
      "./results/bus_stop_data_analysis_dwell_88.csv\n",
      "./results/bus_stop_data_analysis_dwell_77.csv\n",
      "./results/bus_stop_data_analysis_dwell_63.csv\n",
      "./results/bus_stop_data_analysis_dwell_49.csv\n",
      "./results/bus_stop_data_analysis_dwell_61.csv\n",
      "./results/bus_stop_data_analysis_dwell_60.csv\n",
      "./results/bus_stop_data_analysis_dwell_48.csv\n",
      "./results/bus_stop_data_analysis_dwell_185.csv\n",
      "./results/bus_stop_data_analysis_dwell_181.csv\n",
      "./results/bus_stop_data_analysis_dwell_70.csv\n",
      "./results/bus_stop_data_analysis_dwell_64.csv\n",
      "./results/bus_stop_data_analysis_dwell_58.csv\n",
      "./results/bus_stop_data_analysis_dwell_65.csv\n",
      "./results/bus_stop_data_analysis_dwell_71.csv\n",
      "./results/bus_stop_data_analysis_dwell_180.csv\n",
      "./results/bus_stop_data_analysis_dwell_182.csv\n",
      "./results/bus_stop_data_analysis_dwell_73.csv\n",
      "./results/bus_stop_data_analysis_dwell_72.csv\n",
      "./results/bus_stop_data_analysis_dwell_66.csv\n",
      "./results/bus_stop_data_analysis_dwell_168.csv\n",
      "./results/bus_stop_data_analysis_dwell_140.csv\n",
      "./results/bus_stop_data_analysis_dwell_522.csv\n",
      "./results/bus_stop_data_analysis_dwell_14.csv\n",
      "./results/bus_stop_data_analysis_dwell_330.csv\n",
      "./results/bus_stop_data_analysis_dwell_16.csv\n",
      "./results/bus_stop_data_analysis_dwell_17.csv\n",
      "./results/bus_stop_data_analysis_dwell_121.csv\n",
      "./results/bus_stop_data_analysis_dwell_323.csv\n",
      "./results/bus_stop_data_analysis_dwell_13.csv\n",
      "./results/bus_stop_data_analysis_dwell_120.csv\n",
      "./results/bus_stop_data_analysis_dwell_122.csv\n",
      "./results/bus_stop_data_analysis_dwell_10.csv\n",
      "./results/bus_stop_data_analysis_dwell_39.csv\n",
      "./results/bus_stop_data_analysis_dwell_321.csv\n"
     ]
    }
   ],
   "source": [
    "routes_shapes['routeShortName'] = routes_shapes['routeShortName'].astype(int)\n",
    "routes_shapes['directionId'] = routes_shapes['directionId'].astype(int)\n",
    "routes_shapes['stopId'] = routes_shapes['stopId'].astype(int)\n",
    "frames = []\n",
    "stops_frames = []\n",
    "missing_rows = []\n",
    "\n",
    "allFiles = glob.glob('.' + \"/results/*.csv\")\n",
    "for file_ in allFiles:\n",
    "    print(file_)\n",
    "    df = pd.read_csv(file_)\n",
    "    route_id = df['route_id'].value_counts().reset_index().head(1)['index'].values[0]\n",
    "    df['route_id'] = route_id  #alternatively df = df.loc[df['route_id'].dropna().index,]\n",
    "    \n",
    "    #Add daily totals.\n",
    "    daily_counts = df.groupby(['STOP_ID','direction_id'])['BOARD_ALL','ALIGHT_ALL','LOAD_ALL'].sum().reset_index().rename(columns={\n",
    "    \"BOARD_ALL\":\"BOARD_ALL_DAILY\",\"ALIGHT_ALL\":\"ALIGHT_ALL_DAILY\",\"LOAD_ALL\":\"LOAD_ALL_DAILY\"})\n",
    "    df = pd.merge(df,daily_counts, how='outer')\n",
    "\n",
    "    df = df.query(\"TIME_PERIOD=='AM Peak'|TIME_PERIOD=='PM Peak'\")\n",
    "    df = df.sort_values(by=['TIME_PERIOD','DIRECTION_NAME','SORT_ORDER'])\n",
    "    df['travel delay'] = df['travel_time_secs_mean'] - df['travel_time_min_secs']\n",
    "    df['activity'] = df['BOARD_ALL'] + df['ALIGHT_ALL']\n",
    "    df['daily activity'] = df['BOARD_ALL_DAILY'] + df['ALIGHT_ALL_DAILY']\n",
    "    df['activity divided by dwell'] = df['activity']/df['dwell_time_secs_mean']\n",
    "    #df['total_sec_delay'] = df['LOAD_ALL']*df['delay_secs_mean'].shift(periods=-1)\n",
    "    df['distance to next stop'] = df['stop_path_length_meters']*[3.28084]\n",
    "    df['distance to next stop'] =  df['distance to next stop'].shift(periods=-1)\n",
    "    df['travel_speed_miles_per_hour'] =  df['travel_speed_miles_per_hour'].shift(periods=-1)\n",
    "    df['travel_time_secs_mean'] =  df['travel_time_secs_mean'].shift(periods=-1)\n",
    "    df['travel_time_min_secs'] =  df['travel_time_min_secs'].shift(periods=-1)\n",
    "    df['travel delay'] =  df['travel delay'].shift(periods=-1)\n",
    "    df['travel_time_secs_std'] =  df['travel_time_secs_std'].shift(periods=-1)\n",
    "    df['boardings per Obs'] = df['BOARD_ALL']/df['percent_stopped']\n",
    "    df['alightings per Obs'] = df['ALIGHT_ALL']/df['percent_stopped']\n",
    "    df['activity per Obs'] = df['activity']/df['percent_stopped']\n",
    "    df['dwell seconds times load'] = df['dwell_time_secs_mean']*df['LOAD_ALL']\n",
    "    df['load divided by ob activity'] = df['LOAD_ALL']/df['activity per Obs']\n",
    "    df['Load times travel delay'] = df['LOAD_ALL']*df['travel delay']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "    df_csv = df.sort_values(by=['TIME_PERIOD','DIRECTION_NAME','SORT_ORDER'])\n",
    "    columns_to_keep = ['STOP_ID', 'TIME_PERIOD','DIRECTION_NAME','route_id','SORT_ORDER','BOARD_ALL', 'ALIGHT_ALL','daily activity','timepoint','TRIPS_ALL','TRIPS_GROSS', 'activity','dwell_time_secs_mean', 'dwell_time_secs_std', 'percent_stopped',\n",
    "                       'boardings per Obs', 'alightings per Obs', 'activity per Obs', 'distance to next stop', 'travel_speed_miles_per_hour', 'travel_time_secs_mean', 'travel_time_min_secs', 'travel delay', \n",
    "                       'travel_time_secs_std', 'LOAD_ALL', 'dwell seconds times load', 'load divided by ob activity', 'activity divided by dwell', 'Load times travel delay', 'direction_id','BOARD_ALL_DAILY', 'ALIGHT_ALL_DAILY', 'LOAD_ALL_DAILY',]\n",
    "    df_csv = df_csv[columns_to_keep]\n",
    "    df_csv.rename(columns={'STOP_ID':'stop id','sec_per_activity':'seconds per activity', 'total_sec_delay':'Total Passanger Delay', \n",
    "                       'travel_time_min_secs':'minimum travel time', 'TIME_PERIOD':'time period', 'DIRECTION_NAME':'direction name', 'SORT_ORDER':'sort order',\n",
    "                       'travel_time_secs_mean':'travel time', 'travel_time_secs_std':'travel time STD', 'delay_secs_mean':'delay time',\n",
    "                       'travel_speed_miles_per_hour':'MPH','dwell_time_secs_mean':'dwell time', 'dwell_time_secs_std':'dwell time std', \n",
    "                       'BOARD_ALL': 'Boardings','ALIGHT_ALL':'Alightings', 'LOAD_ALL':'Load' },inplace=True)\n",
    "\n",
    "    df_csv = pd.merge(df_csv,geo_df[['trapeze_id','stopname', 'st_loc', 'routes_listed']],left_on=['stop id'],right_on=['trapeze_id'], how='left')\n",
    "\n",
    "    df_csv.sort_values(by=['time period','direction name','sort order']).to_csv(\"fast_output/fast_output_\" + file_.split('_')[-1], index=False)\n",
    "    frames.append(df_csv.copy())\n",
    "\n",
    "    stops_columns_to_keep = ['stop id', 'time period', 'direction name', 'timepoint', 'Boardings',\n",
    "       'Alightings', 'activity','daily activity','dwell time', 'dwell time std',\n",
    "       'percent_stopped', 'boardings per Obs', 'alightings per Obs',\n",
    "       'activity per Obs', 'distance to next stop', 'Load',\n",
    "       'dwell seconds times load', 'load divided by ob activity',\n",
    "       'activity divided by dwell', 'trapeze_id',\n",
    "       'stopname', 'st_loc', 'route_id','routes_listed']    \n",
    "    df_stops_geojson = pd.merge(df_csv[stops_columns_to_keep],geo_df[['trapeze_id','rtiid', 'geometry']],left_on=['trapeze_id'],right_on=['trapeze_id'])\n",
    "    stops_frames.append(df_stops_geojson)\n",
    "    \n",
    "#     df_stops_geojson = pd.merge(df[stops_columns_to_keep],geo_df[['trapeze_id','stopname','rtiid', 'geometry']],left_on=['STOP_ID'],right_on=['trapeze_id'])\n",
    "#     stops_frames.append(df_stops_geojson)\n",
    "#     missing_row = pd.merge(df, routes_shapes, left_on=['route_id','direction_id','STOP_ID'],right_on=['routeShortName','directionId','stopId'], how='left', indicator=True).query(\"_merge!='both'\")\n",
    "#     missing_rows.append(missing_row)\n",
    "\n",
    "pd.concat(frames,ignore_index=True).to_csv(\"fast_output/full_routes.csv\",index=False)\n",
    "df_all = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "stops_df = pd.concat(stops_frames,ignore_index=True)\n",
    "stops_df.rename(columns=lambda x: x.replace(' ','_'), inplace=True)\n",
    "stops_df = gpd.GeoDataFrame(stops_df, crs = crs).set_geometry(stops_df['geometry'])\n",
    "\n",
    "try:\n",
    "    os.remove('fast_geospatial_output/stops_df.geojson')\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove('fast_geospatial_output/shapes_data.geojson')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('fast_geospatial_output/stops_df/')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree('fast_geospatial_output/shapes_data/')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "stops_df.to_file('fast_geospatial_output/stops_df.geojson',driver='GeoJSON')\n",
    "stops_df.to_file('fast_geospatial_output/stops_df',driver='ESRI Shapefile')\n",
    "\n",
    "shapes_data = pd.merge(df_all, routes_shapes, left_on=['route_id','direction_id','stop id'],right_on=['routeShortName','directionId','stopId'], how='left')\n",
    "shapes_data.rename(columns=lambda x: x.replace(' ','_'), inplace=True)\n",
    "shapes_data = shapes_data.loc[~shapes_data['geometry'].isnull(),]\n",
    "shapes_data = gpd.GeoDataFrame(shapes_data, crs = crs).set_geometry(shapes_data['geometry'])\n",
    "shapes_data.to_file('fast_geospatial_output/shapes_data.geojson',driver='GeoJSON')\n",
    "shapes_data.to_file('fast_geospatial_output/shapes_data',driver='ESRI Shapefile')\n",
    "\n",
    "# pd.concat(missing_rows).to_csv('missing_data_rows.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
