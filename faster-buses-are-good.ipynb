{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab relevant information for bus stops for a specific route, join the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import pymssql\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "SWIFTLY_API_KEY = config['DEFAULT']['SWIFTLY_API_KEY']\n",
    "MSSQL_USERNAME = config['DEFAULT']['MSSQL_USERNAME']\n",
    "MSSQL_PASSWORD = config['DEFAULT']['MSSQL_PASSWORD']\n",
    "\n",
    "connection = pymssql.connect(server='ELTDBPRD\\ELTDBPRD', user=MSSQL_USERNAME, password=MSSQL_PASSWORD, database='ACS_13')\n",
    "# mssql_login = config['DEFAULT']['MSSQL_AMIGO_ADMIN']\n",
    "\n",
    "# DEBUG = True\n",
    "\n",
    "# October dates [2,3,4,5,9,10,11,12,16,17,18,19,23,24,25,26,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_ridership_by_stop(line_number):\n",
    "\n",
    "    # allFiles = glob.glob('.' + \"/gps_*.csv\")\n",
    "    frame = pd.DataFrame()\n",
    "    frames = []\n",
    "    for file_ in ['Ridership/WEEKDAY.XLSX','Ridership/LRTWEEKDAY.XLSX']:\n",
    "        df = pd.read_excel(file_, header=0)\n",
    "        df['DAY']='RS_WKDY'\n",
    "        #     df['DAY']='Weekday'\n",
    "        frames.append(df)\n",
    "    # for file_ in ['Ridership/SATURDAY.XLSX','Ridership/LRTSATURDAY.XLSX']:\n",
    "    #     df = pd.read_excel(file_, header=0)\n",
    "    #     df['DAY']='RS_SAT'\n",
    "    #     frames.append(df)\n",
    "    # for file_ in ['Ridership/SUNDAY.XLSX','Ridership/LRTSUNDAY.XLSX']:\n",
    "    #     df = pd.read_excel(file_, header=0)\n",
    "    #     df['DAY']='RS_SUN'\n",
    "    #     frames.append(df)\n",
    "\n",
    "    df = pd.concat(frames)\n",
    "    df = df[~df['ROUTE_NUMBER'].isin([911,912,913,914])]\n",
    "\n",
    "    df = df.query(\"DAY=='RS_WKDY'&ROUTE_NUMBER=='%d'\" % line_number)\n",
    "\n",
    "    #     pd.pivot_table(df.reset_index(), index=[\"STOP_ID\"],values=[\"BOARD_ALL\",'ALIGHT_ALL']).head()\n",
    "\n",
    "    rid_line = pd.pivot_table(df.reset_index(), index=[\"STOP_ID\",\"DIRECTION_NAME\",\"TIME_PERIOD\"],values=[\"SORT_ORDER\",\"BOARD_ALL\",'ALIGHT_ALL','LOAD_ALL','AVG_SERVICED','TIME_PERIOD_SORT']).reset_index().sort_values(by=['DIRECTION_NAME','TIME_PERIOD_SORT','SORT_ORDER'])\n",
    "    rid_line['ALIGHT_ALL']= rid_line['ALIGHT_ALL'].round(2)\n",
    "    rid_line['AVG_SERVICED'] = rid_line['AVG_SERVICED'].round(2)\n",
    "    rid_line['BOARD_ALL'] = rid_line['BOARD_ALL'].round(2)\n",
    "    rid_line['LOAD_ALL'] = rid_line['LOAD_ALL'].round(2)\n",
    "    return rid_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_early_late_by_stop(line_number,SWIFTLY_API_KEY, dateRange, timeRange):\n",
    "    '''http://dashboard.goswift.ly/vta/api-guide/docs/otp'''\n",
    "#     line_number = '22'\n",
    "#     dateRange = '10012017-10302017'\n",
    "#     timeRange = '0500-0900'\n",
    "    line_table = pd.read_csv('line_table.csv')\n",
    "    line_table.rename(columns={\"DirNum\":\"direction_id\",\"DirectionName\":\"DIRECTION_NAME\"},inplace=True)\n",
    "    line_table['direction_id'] = line_table['direction_id'].astype(str)\n",
    "    headers = {'Authorization': SWIFTLY_API_KEY}\n",
    "    payload = {'agency': 'vta', 'route': line_number, 'dateRange': dateRange,'timeRange': timeRange, 'onlyScheduleAdherenceStops':'True'}\n",
    "    # payload = {'agency': 'vta', 'dateRange': '10292017-10302017'}\n",
    "    url = 'https://api.goswift.ly/otp/by-stop'\n",
    "    r = requests.get(url, headers=headers, params=payload)\n",
    "    print(r.text)\n",
    "    try:\n",
    "        swiftly_df = pd.DataFrame(r.json()['data'])\n",
    "        swiftly_df.rename(columns={\"stop_id\":\"STOP_ID\"},inplace=True)\n",
    "        swiftly_df = pd.merge(swiftly_df,line_table.query('lineabbr==%s'%line_number)[['direction_id','DIRECTION_NAME']])\n",
    "        swiftly_df['STOP_ID'] = swiftly_df['STOP_ID'].astype(int)\n",
    "        return swiftly_df\n",
    "    except KeyError:\n",
    "        print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_frequency_percent():\n",
    "    sql = '''select current_route_id, k.direction_code_id, dc.[direction_description], sum(count_trips) as unique_trips_sampled from (\n",
    "SELECT [direction_code_id], current_route_id\n",
    "      ,count(distinct(ext_trip_id)) as 'count_trips'\n",
    "      ,datepart(dy, [apc_date_time]) as 'dayofyear'\n",
    "      /*,cast(floor(cast([apc_date_time] as float)) as datetime) as indate*/\n",
    "      FROM [ACS_13].[dbo].[apc_correlated] where \n",
    "  (apc_date_time between '2017-10-03' and '2017-10-06' or \n",
    "  apc_date_time between '2017-10-10' and '2017-10-13' or \n",
    "  apc_date_time between '2017-10-17' and '2017-10-20' or\n",
    "  apc_date_time between '2017-10-24' and '2017-10-27' or\n",
    "  apc_date_time between '2017-10-31' and '2017-11-1') and \n",
    "  current_route_id = 22 \n",
    "  and bs_id != 0\n",
    "  group by current_route_id, direction_code_id ,datepart(dy, [apc_date_time])\n",
    "  ) k \n",
    "  LEFT join [ACS_13].[dbo].[direction_codes] dc\n",
    "  on k.direction_code_id = dc.[direction_code_id]\n",
    "\n",
    "  group by current_route_id, k.direction_code_id, dc.[direction_description]'''\n",
    "\n",
    "    trips_sampled = pd.read_sql(sql,connection)\n",
    "    \n",
    "    sql = '''SELECT [direction_code_id]\n",
    "      , [bs_id],\n",
    "      count(bs_id) as 'number of times stopped'\n",
    "      FROM [ACS_13].[dbo].[apc_correlated] where \n",
    "  (apc_date_time between '2017-10-03' and '2017-10-06' or \n",
    "  apc_date_time between '2017-10-10' and '2017-10-13' or \n",
    "  apc_date_time between '2017-10-17' and '2017-10-20' or\n",
    "  apc_date_time between '2017-10-24' and '2017-10-27' or\n",
    "  apc_date_time between '2017-10-31' and '2017-11-1') and \n",
    "  current_route_id = 22 \n",
    "  and bs_id != 0\n",
    "  group by direction_code_id, bs_id\n",
    "  order by direction_code_id, bs_id'''\n",
    "\n",
    "    number_of_times_stopped_in_period = pd.read_sql(sql,connection)\n",
    "    stopped_frequency = pd.merge(number_of_times_stopped_in_period, trips_sampled)\n",
    "    \n",
    "    stopped_frequency['% frequency stopped'] = (stopped_frequency['number of times stopped']/stopped_frequency['unique_trips_sampled']).round(2)\n",
    "    stopped_frequency.rename(columns={\"bs_id\":\"STOP_ID\",\"direction_description\":\"DIRECTION_NAME\"},inplace=True)\n",
    "\n",
    "    return stopped_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwell_runtime(line_number):\n",
    "    line_number = 22\n",
    "    allFiles = glob.glob('.' + \"/swiftly data oct/*.csv\")\n",
    "    frame = pd.DataFrame()\n",
    "    frames = []\n",
    "    # check for Too many lines errors\n",
    "    # count = 0\n",
    "    # for file_ in allFiles:\n",
    "    #     count = count + 1\n",
    "    #     print(file_, read_first_lines(file_, 1))\n",
    "    for file_ in allFiles:\n",
    "        df = pd.read_csv(file_)\n",
    "        frames.append(df)\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df['time'] = pd.to_datetime(df['actual_date'] + ' ' + df['actual_time'], format='%m-%d-%y %H:%M:%S')\n",
    "\n",
    "    # 1430-1829 = pm peak\n",
    "    def TIME_PERIOD(x):\n",
    "    #     if df['time'].dt.hour >= 5 and df['time'].dt.hour <= 8:\n",
    "        if x.hour >= 5 and x.hour <= 8:\n",
    "            return 'AM Peak'\n",
    "        elif x.hour >= 14 and x.hour <= 18:\n",
    "            return 'PM Peak'\n",
    "        else:\n",
    "            return 'Neither time zone'\n",
    "\n",
    "    df = df.query(\"route_id=='%d'\" % line_number)\n",
    "    df['TIME_PERIOD'] = df['time'].apply(TIME_PERIOD)\n",
    "\n",
    "    f = {'dwell_time_secs':['mean','std','size']}\n",
    "    # .size()\n",
    "    df_dwell = df.query(\"route_id=='%d'&is_departure==True\" % line_number).groupby(['route_id','direction_id','TIME_PERIOD','stop_id']).agg(f)\n",
    "\n",
    "    f = {'travel_time_secs':['mean','std','size']}\n",
    "    df_runtime = df.query(\"route_id=='%d'&is_departure==False\" % line_number).groupby(['route_id','direction_id','TIME_PERIOD','stop_id']).agg(f)\n",
    "\n",
    "    df_results = pd.merge(df_dwell.reset_index(), df_runtime.reset_index())\n",
    "    # , 'B':['prod']\n",
    "\n",
    "    line_table = pd.read_csv('line_table.csv')\n",
    "    line_table.rename(columns={\"DirNum\":\"direction_id\",\"DirectionName\":\"DIRECTION_NAME\", \"lineabbr\":\"route_id\"},inplace=True)\n",
    "    line_table['direction_id'] = line_table['direction_id'].astype(int)\n",
    "    # line_table.direction_id = line_table.direction_id.astype(int)\n",
    "    df_results = pd.merge(df_dwell.reset_index(), df_runtime.reset_index())\n",
    "    df_results.rename(columns={'dwell_time_secs':'dwell_time_secs_','travel_time_secs':'travel_time_secs_'},inplace=True)\n",
    "    df_results.columns = [''.join(t) for t in df_results.columns]\n",
    "    df_results = pd.merge(df_results,df.groupby(['route_id','direction_id','stop_id'])['stop_path_length_meters'].max().reset_index(),how='left')\n",
    "    df_results.rename(columns={'stop_id':'STOP_ID'},inplace=True)\n",
    "    return pd.merge(df_results,line_table, how='left', left_on = ['route_id','direction_id'], right_on = ['route_id','direction_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>DIRECTION_NAME</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>ALIGHT_ALL</th>\n",
       "      <th>AVG_SERVICED</th>\n",
       "      <th>BOARD_ALL</th>\n",
       "      <th>LOAD_ALL</th>\n",
       "      <th>SORT_ORDER</th>\n",
       "      <th>TIME_PERIOD_SORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>328</td>\n",
       "      <td>EAST</td>\n",
       "      <td>AM Early</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>43.87</td>\n",
       "      <td>43.99</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>329</td>\n",
       "      <td>EAST</td>\n",
       "      <td>AM Early</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.64</td>\n",
       "      <td>44.62</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>330</td>\n",
       "      <td>EAST</td>\n",
       "      <td>AM Early</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>44.79</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>331</td>\n",
       "      <td>EAST</td>\n",
       "      <td>AM Early</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>44.83</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>332</td>\n",
       "      <td>EAST</td>\n",
       "      <td>AM Early</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.83</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STOP_ID DIRECTION_NAME TIME_PERIOD  ALIGHT_ALL  AVG_SERVICED  BOARD_ALL  \\\n",
       "186      328           EAST    AM Early        0.49          0.99      43.87   \n",
       "192      329           EAST    AM Early        0.00          0.19       0.64   \n",
       "198      330           EAST    AM Early        0.00          0.05       0.16   \n",
       "204      331           EAST    AM Early        0.00          0.01       0.04   \n",
       "210      332           EAST    AM Early        0.00          0.00       0.00   \n",
       "\n",
       "     LOAD_ALL  SORT_ORDER  TIME_PERIOD_SORT  \n",
       "186     43.99          10                 1  \n",
       "192     44.62          20                 1  \n",
       "198     44.79          30                 1  \n",
       "204     44.83          40                 1  \n",
       "210     44.83          50                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid_by_stop_df = pull_ridership_by_stop(22)\n",
    "rid_by_stop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dwell_runtime = dwell_runtime(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid_dwell = pd.merge(rid_by_stop_df,df_dwell_runtime,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Midday - 9 to 2:30\n",
    "# PM Peak - 2:30 to 6:30\n",
    "# PM Late - 6:30 to 9:59\n",
    "# PM Nite - 10pm to 12pm\n",
    "# PM Nite - 12am to 3am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "# df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '0300-0459')\n",
    "# df['TIME_PERIOD'] = 'AM Early'\n",
    "# frames.append(df)\n",
    "# time.sleep(10)\n",
    "df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '0500-0829')\n",
    "df['TIME_PERIOD'] = 'AM Peak'\n",
    "frames.append(df)\n",
    "time.sleep(10)\n",
    "# df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '0900-1429')\n",
    "# df['TIME_PERIOD'] = 'Midday'\n",
    "# frames.append(df)\n",
    "# time.sleep(10)\n",
    "df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '1430-1829')\n",
    "df['TIME_PERIOD'] = 'PM Peak'\n",
    "frames.append(df)\n",
    "# time.sleep(10)\n",
    "# df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '1830-2199')\n",
    "# df['TIME_PERIOD'] = 'PM Late'\n",
    "# frames.append(df)\n",
    "# time.sleep(10)\n",
    "# df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '2200-2359')\n",
    "# df['TIME_PERIOD'] = 'PM Nite'\n",
    "# frames.append(df)\n",
    "# time.sleep(10)\n",
    "# df = pull_early_late_by_stop('22',SWIFTLY_API_KEY, dateRange = '10012017-10302017', timeRange = '0000-0259')\n",
    "# df['TIME_PERIOD'] = 'PM Nite'\n",
    "# frames.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.concat(frames)\n",
    "times['TIMEPOINT'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bus_df = pd.merge(rid_dwell,times, how='outer', on=['STOP_ID','DIRECTION_NAME','TIME_PERIOD'])\n",
    "# bus_df.to_csv(\"bus_analysis.csv\",index=False)\n",
    "# bus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_frequency = stop_frequency_percent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus_df\n",
    "bus_df_frequency = pd.merge(rid_dwell, stop_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df_frequency.to_csv(\"bus_analysis.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus_df_frequency.query('TIMEPOINT==True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
