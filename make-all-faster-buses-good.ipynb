{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Processing\n",
    "### Grab relevant information for bus stops for a specific route, join the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import platform\n",
    "# from analysis_functions import *\n",
    "from analysis_functions import read_in_dwell_runtime, timepoint_finder \n",
    "from analysis_functions import pull_ridership_by_stop, dwell_runtime, stop_frequency_percent\n",
    "\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "SWIFTLY_API_KEY = config['DEFAULT']['SWIFTLY_API_KEY']\n",
    "MSSQL_USERNAME = config['DEFAULT']['MSSQL_USERNAME']\n",
    "MSSQL_PASSWORD = config['DEFAULT']['MSSQL_PASSWORD']\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    import pymssql\n",
    "    connection = pymssql.connect(server='ELTDBPRD\\ELTDBPRD', \n",
    "        user=MSSQL_USERNAME, password=MSSQL_PASSWORD, database='ACS_13')\n",
    "elif platform.system() == 'Windows':\n",
    "    import pyodbc\n",
    "    connection_string = 'DRIVER={SQL Server};SERVER=ELTDBPRD\\ELTDBPRD;DATABASE=ACS_13;UID=%s;PWD=%s' % (MSSQL_USERNAME, MSSQL_PASSWORD)\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "\n",
    "\n",
    "# DEBUG = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_numbers = [\n",
    "    22, 181, 68, 23, 66, 25, 10, 200, 55, 304, 19,\n",
    "    64, 72, 70, 180, 62, 71, 57, 121, 168, 26, 60, \n",
    "    102, 27, 35, 48, 65, 32, 328, 103, 104, 522, 61, \n",
    "    122, 77, 73, 46, 101, 54, 88, 89, 40, 81, 52, 53, \n",
    "    58, 31, 63, 323, 82, 47, 120, 182, 201, 330, 140, \n",
    "    49, 37, 16, 13, 42, 18, 14, 17, 45, 39, 321, 185, \n",
    "    34, 900, 901, 902\n",
    "    ]\n",
    "\n",
    "# Skip VTA special lines 831, 827, 828, 826, 825, 823, 95, 12, 231, 235\n",
    "\n",
    "\n",
    "days_to_consider = [2,3,4,5,9,10,11,12,16,17,18,19,23,24,25,26,30]\n",
    "month_to_consider = 10\n",
    "year_to_consider = 2018\n",
    "date_range_to_consider = \"'2017-10-01' and '2017-11-1'\"\n",
    "\n",
    "transitfeeds_url_relevant_gtfs = 'http://transitfeeds.com/p/vta/45/20170929/download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "swiftly_source_data_df = read_in_dwell_runtime(month=month_to_consider, year=year_to_consider)\n",
    "timepoints = timepoint_finder(transitfeeds_url = transitfeeds_url_relevant_gtfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for line_number in line_numbers:\n",
    "    print(line_number)\n",
    "    rid_by_stop_df = pull_ridership_by_stop(line_number)\n",
    "    rid_by_stop_df.head()\n",
    "\n",
    "    df_dwell_runtime, df_stop_path_length, df_min_travel_time = dwell_runtime(swiftly_source_data_df, line_number, days_to_consider)\n",
    "\n",
    "    rid_dwell = pd.merge(pd.merge(pd.merge(rid_by_stop_df,df_dwell_runtime,how='outer'),df_stop_path_length, how='outer'),df_min_travel_time, how='outer')\n",
    "\n",
    "    stops_visited_counts, trips_sampled_count = stop_frequency_percent(connection, line_number, days_to_consider, date_range= date_range_to_consider)\n",
    "    del stops_visited_counts['current_route_id']\n",
    "    del trips_sampled_count['current_route_id']\n",
    "\n",
    "    bus_df_frequency = pd.merge(pd.merge(rid_dwell, stops_visited_counts, how=\"outer\"),trips_sampled_count, how=\"outer\")\n",
    "    # stop_frequency['percent_stopped'] = (stop_frequency['number_of_times_stopped']/stop_frequency['total_trips_sampled']).round(2)\n",
    "    # bus_df_frequency['percent_stopped'] = (bus_df_frequency['number_of_times_stopped'].dividebus_df_frequency['total_trips_sampled']).round(2)\n",
    "    bus_df_frequency['percent_stopped'] = (bus_df_frequency['number_of_times_stopped'].divide(bus_df_frequency['total_trips_sampled'],fill_value=0)).round(2)\n",
    "\n",
    "    bus_df_frequency['travel_speed_meters_second'] = (bus_df_frequency['stop_path_length_meters']/bus_df_frequency['travel_time_secs_mean']).round(2)\n",
    "    bus_df_frequency['travel_speed_miles_per_hour'] = ((bus_df_frequency['stop_path_length_meters']/bus_df_frequency['travel_time_secs_mean'])*2.23694).round(2)\n",
    "    \n",
    "    bus_df_frequency['route_id']=line_number\n",
    "\n",
    "    bus_array = pd.merge(bus_df_frequency,timepoints, how='left')\n",
    "    bus_array.loc[bus_array['timepoint'].isnull(),'timepoint'] = 0\n",
    "    \n",
    "    bus_array.to_csv(\"results/bus_stop_data_analysis_dwell_\" + str(line_number) + \".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
